{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom random import shuffle\nimport torch\nfrom torch import nn\nimport math\nfrom glob import glob\nimport sys\nimport shutil  \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-27T09:45:18.226598Z","iopub.execute_input":"2022-04-27T09:45:18.226887Z","iopub.status.idle":"2022-04-27T09:45:18.236626Z","shell.execute_reply.started":"2022-04-27T09:45:18.226855Z","shell.execute_reply":"2022-04-27T09:45:18.235900Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.utils.data\nimport torchvision.transforms as transforms\nimport PIL\nimport random\nfrom scipy import ndimage\n\n\nclass segDataset(torch.utils.data.Dataset):\n    def __init__(self, root, training, transform=None):\n        super(segDataset, self).__init__()\n        self.root = root\n        self.training = training\n        self.transform = transform\n        self.IMG_NAMES = sorted(glob(self.root + '/*/images/*.jpg'))\n        self.BGR_classes = {'Water' : [ 41, 169, 226],\n                            'Land' : [246,  41, 132],\n                            'Road' : [228, 193, 110],\n                            'Building' : [152,  16,  60], \n                            'Vegetation' : [ 58, 221, 254],\n                            'Unlabeled' : [155, 155, 155]}\n\n        self.bin_classes = ['Water', 'Land', 'Road', 'Building', 'Vegetation', 'Unlabeled']\n\n\n    def __getitem__(self, idx):\n        img_path = self.IMG_NAMES[idx]\n        mask_path = img_path.replace('images', 'masks').replace('.jpg', '.png')\n\n        image = cv2.imread(img_path)\n        mask = cv2.imread(mask_path)\n        cls_mask = np.zeros(mask.shape)  \n        cls_mask[mask == self.BGR_classes['Water']] = self.bin_classes.index('Water')\n        cls_mask[mask == self.BGR_classes['Land']] = self.bin_classes.index('Land')\n        cls_mask[mask == self.BGR_classes['Road']] = self.bin_classes.index('Road')\n        cls_mask[mask == self.BGR_classes['Building']] = self.bin_classes.index('Building')\n        cls_mask[mask == self.BGR_classes['Vegetation']] = self.bin_classes.index('Vegetation')\n        cls_mask[mask == self.BGR_classes['Unlabeled']] = self.bin_classes.index('Unlabeled')\n        cls_mask = cls_mask[:,:,0] \n\n        if self.training==True:\n\n            # 90 degree rotation\n            if np.random.rand()<0.5:\n              angle = np.random.randint(4) * 90\n              image = ndimage.rotate(image,angle,reshape=True)\n              cls_mask = ndimage.rotate(cls_mask,angle,reshape=True)\n\n            # vertical flip\n            if np.random.rand()<0.5:\n              image = np.flip(image, 0)\n              cls_mask = np.flip(cls_mask, 0)\n            \n            # horizonal flip\n            if np.random.rand()<0.5:\n              image = np.flip(image, 1)\n              cls_mask = np.flip(cls_mask, 1)\n\n        image = cv2.resize(image, (512,512))/255.0\n        cls_mask = cv2.resize(cls_mask, (512,512)) \n        image = np.moveaxis(image, -1, 0)\n\n        return torch.tensor(image).float(), torch.tensor(cls_mask, dtype=torch.int64)\n\n\n    def __len__(self):\n        return len(self.IMG_NAMES)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:45:18.267267Z","iopub.execute_input":"2022-04-27T09:45:18.267580Z","iopub.status.idle":"2022-04-27T09:45:18.446635Z","shell.execute_reply.started":"2022-04-27T09:45:18.267548Z","shell.execute_reply":"2022-04-27T09:45:18.445855Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"t = transforms.Compose([])\ndataset = segDataset('../input/fivpdataset', training = True, transform= t)\n\nlen(dataset)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:45:18.448494Z","iopub.execute_input":"2022-04-27T09:45:18.448945Z","iopub.status.idle":"2022-04-27T09:45:18.474180Z","shell.execute_reply.started":"2022-04-27T09:45:18.448889Z","shell.execute_reply":"2022-04-27T09:45:18.473555Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"d = dataset[7]\nplt.figure(figsize=(15,15))\nplt.subplot(1,2,1)\nplt.imshow(np.moveaxis(d[0].numpy(),0,-1))\nplt.subplot(1,2,2)\nplt.imshow(d[1].numpy())","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:45:18.475294Z","iopub.execute_input":"2022-04-27T09:45:18.475599Z","iopub.status.idle":"2022-04-27T09:45:19.290370Z","shell.execute_reply.started":"2022-04-27T09:45:18.475563Z","shell.execute_reply":"2022-04-27T09:45:19.289767Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"test_num = int(0.1 * len(dataset))\nprint(f'test data : {test_num}')\ntrain_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset)-test_num, test_num], generator=torch.Generator().manual_seed(101))","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:45:19.292252Z","iopub.execute_input":"2022-04-27T09:45:19.292929Z","iopub.status.idle":"2022-04-27T09:45:19.299730Z","shell.execute_reply.started":"2022-04-27T09:45:19.292893Z","shell.execute_reply":"2022-04-27T09:45:19.299027Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"BACH_SIZE = 4\n\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BACH_SIZE, shuffle=True, num_workers=4)\n\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BACH_SIZE, shuffle=False, num_workers=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:45:19.301125Z","iopub.execute_input":"2022-04-27T09:45:19.301772Z","iopub.status.idle":"2022-04-27T09:45:19.309164Z","shell.execute_reply.started":"2022-04-27T09:45:19.301733Z","shell.execute_reply":"2022-04-27T09:45:19.308273Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass DoubleConv(nn.Module):\n    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n\n    def __init__(self, in_channels, out_channels, mid_channels=None):\n        super().__init__()\n        if not mid_channels:\n            mid_channels = out_channels\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(mid_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\n\nclass Down(nn.Module):\n    \"\"\"Downscaling with maxpool then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_channels, out_channels)\n        )\n\n    def forward(self, x):\n        return self.maxpool_conv(x)\n\n\nclass Up(nn.Module):\n    \"\"\"Upscaling then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels, bilinear=True):\n        super().__init__()\n\n        if bilinear:\n            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n        else:\n            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n            self.conv = DoubleConv(in_channels, out_channels)\n\n\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n        # input is CHW\n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n\n        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n                        diffY // 2, diffY - diffY // 2])\n        x = torch.cat([x2, x1], dim=1)\n        return self.conv(x)\n\n\nclass OutConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(OutConv, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n\n    def forward(self, x):\n        return self.conv(x)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:45:19.310896Z","iopub.execute_input":"2022-04-27T09:45:19.311394Z","iopub.status.idle":"2022-04-27T09:45:19.332119Z","shell.execute_reply.started":"2022-04-27T09:45:19.311357Z","shell.execute_reply":"2022-04-27T09:45:19.331322Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self, n_channels, n_classes, bilinear=True):\n        super(UNet, self).__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.bilinear = bilinear\n\n        self.inc = DoubleConv(n_channels, 64)\n        self.down1 = Down(64, 128)\n        self.down2 = Down(128, 256)\n        self.down3 = Down(256, 512)\n        factor = 2 if bilinear else 1\n        self.down4 = Down(512, 1024 // factor)\n        self.up1 = Up(1024, 512 // factor, bilinear)\n        self.up2 = Up(512, 256 // factor, bilinear)\n        self.up3 = Up(256, 128 // factor, bilinear)\n        self.up4 = Up(128, 64, bilinear)\n        self.outc = OutConv(64, n_classes)\n\n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x = self.up1(x5, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)\n        logits = self.outc(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:45:19.333453Z","iopub.execute_input":"2022-04-27T09:45:19.333851Z","iopub.status.idle":"2022-04-27T09:45:19.346135Z","shell.execute_reply.started":"2022-04-27T09:45:19.333815Z","shell.execute_reply":"2022-04-27T09:45:19.345324Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=0, alpha=None, size_average=True):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n        self.size_average = size_average\n\n    def forward(self, input, target):\n        if input.dim()>2:\n            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n        target = target.view(-1,1)\n\n        logpt = F.log_softmax(input, dim=-1)\n        logpt = logpt.gather(1,target)\n        logpt = logpt.view(-1)\n        pt = Variable(logpt.data.exp())\n\n        if self.alpha is not None:\n            if self.alpha.type()!=input.data.type():\n                self.alpha = self.alpha.type_as(input.data)\n            at = self.alpha.gather(0,target.data.view(-1))\n            logpt = logpt * Variable(at)\n\n        loss = -1 * (1-pt)**self.gamma * logpt\n        if self.size_average: return loss.mean()\n        else: return loss.sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:45:19.347571Z","iopub.execute_input":"2022-04-27T09:45:19.347927Z","iopub.status.idle":"2022-04-27T09:45:19.360850Z","shell.execute_reply.started":"2022-04-27T09:45:19.347888Z","shell.execute_reply":"2022-04-27T09:45:19.359912Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"criterion = FocalLoss(gamma=3/4).to(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:45:19.362592Z","iopub.execute_input":"2022-04-27T09:45:19.362848Z","iopub.status.idle":"2022-04-27T09:45:19.374084Z","shell.execute_reply.started":"2022-04-27T09:45:19.362815Z","shell.execute_reply":"2022-04-27T09:45:19.373169Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def acc(label, predicted):\n  seg_acc = (y.cpu() == torch.argmax(pred_mask, axis=1).cpu()).sum() / torch.numel(y.cpu())\n  return seg_acc","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:45:19.378181Z","iopub.execute_input":"2022-04-27T09:45:19.378391Z","iopub.status.idle":"2022-04-27T09:45:19.384701Z","shell.execute_reply.started":"2022-04-27T09:45:19.378360Z","shell.execute_reply":"2022-04-27T09:45:19.383983Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"min_loss = torch.tensor(float('inf'))\n\nmodel = UNet(n_channels=3, n_classes=6, bilinear=True).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:45:19.385867Z","iopub.execute_input":"2022-04-27T09:45:19.386184Z","iopub.status.idle":"2022-04-27T09:45:19.554260Z","shell.execute_reply.started":"2022-04-27T09:45:19.386148Z","shell.execute_reply":"2022-04-27T09:45:19.553526Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./saved_models', exist_ok=True)\n\nN_EPOCHS = 15\nN_DATA = len(train_dataset)\nN_TEST = len(test_dataset)\n\nplot_losses = []\nscheduler_counter = 0\n\nfor epoch in range(N_EPOCHS):\n  # training\n  model.train()\n  loss_list = []\n  acc_list = []\n  for batch_i, (x, y) in enumerate(train_dataloader):\n\n      pred_mask = model(x.to(device))  \n      loss = criterion(pred_mask, y.to(device))\n\n      optimizer.zero_grad()\n      loss.backward()\n      optimizer.step()\n      loss_list.append(loss.cpu().detach().numpy())\n      acc_list.append(acc(y,pred_mask).numpy())\n\n      sys.stdout.write(\n          \"\\r[Epoch %d/%d] [Batch %d/%d] [Loss: %f (%f)]\"\n          % (\n              epoch,\n              N_EPOCHS,\n              batch_i,\n              len(train_dataloader),\n              loss.cpu().detach().numpy(),\n              np.mean(loss_list),\n          )\n      )\n  scheduler_counter += 1\n  # testing\n  model.eval()\n  val_loss_list = []\n  val_acc_list = []\n  for batch_i, (x, y) in enumerate(test_dataloader):\n      with torch.no_grad():    \n          pred_mask = model(x.to(device))  \n      val_loss = criterion(pred_mask, y.to(device))\n      val_loss_list.append(val_loss.cpu().detach().numpy())\n      val_acc_list.append(acc(y,pred_mask).numpy())\n    \n  print(' epoch {} - loss : {:.5f} - acc : {:.2f} - val loss : {:.5f} - val acc : {:.2f}'.format(epoch,np.mean(loss_list),np.mean(acc_list),np.mean(val_loss_list),np.mean(val_acc_list)))\n  \n  plot_losses.append([epoch, np.mean(loss_list), np.mean(val_loss_list)])\n\n  compare_loss = np.mean(val_loss_list)\n  is_best = compare_loss < min_loss\n  if is_best == True:\n    scheduler_counter = 0\n    min_loss = min(compare_loss, min_loss)\n    torch.save(model.state_dict(), './saved_models/unet_epoch_{}_{:.5f}.pt'.format(epoch,np.mean(val_loss_list)))\n  \n  if scheduler_counter > 5:\n    lr_scheduler.step()\n    print(f\"lowering learning rate to {optimizer.param_groups[0]['lr']}\")\n    scheduler_counter = 0\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:45:19.555743Z","iopub.execute_input":"2022-04-27T09:45:19.555993Z","iopub.status.idle":"2022-04-27T09:55:35.206462Z","shell.execute_reply.started":"2022-04-27T09:45:19.555959Z","shell.execute_reply":"2022-04-27T09:55:35.204779Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('./saved_models/unet_epoch_14_0.54148.pt'))","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:56:09.860569Z","iopub.execute_input":"2022-04-27T09:56:09.860844Z","iopub.status.idle":"2022-04-27T09:56:09.923171Z","shell.execute_reply.started":"2022-04-27T09:56:09.860813Z","shell.execute_reply":"2022-04-27T09:56:09.922462Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\nfor batch_i, (x, y) in enumerate(test_dataloader):\n    for j in range(len(x)):\n        result = model(x.to(device)[j:j+1])\n        mask = torch.argmax(result, axis=1).cpu().detach().numpy()[0]\n        im = np.moveaxis(x.to(device)[j].cpu().detach().numpy(), 0, -1).copy()*255\n        im = im.astype(int)\n        gt_mask = y[j]\n\n        plt.figure(figsize=(12,12))\n\n        plt.subplot(1,2,1)\n        im = np.moveaxis(x.to(device)[j].cpu().detach().numpy(), 0, -1).copy()*255\n        im = im.astype(int)\n        plt.imshow(im)\n\n        plt.subplot(1,2,2)\n        plt.imshow(mask)\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:56:11.590318Z","iopub.execute_input":"2022-04-27T09:56:11.590900Z","iopub.status.idle":"2022-04-27T09:56:18.380248Z","shell.execute_reply.started":"2022-04-27T09:56:11.590862Z","shell.execute_reply":"2022-04-27T09:56:18.379430Z"},"trusted":true},"execution_count":43,"outputs":[]}]}